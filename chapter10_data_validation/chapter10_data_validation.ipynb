{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Data Validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Is Data Validation Essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data with mixed age types\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [1, 2, 3, 4, 5],\n",
    "        \"age\": [25, \"30\", 35, \"40\", 45], # Some values are strings\n",
    "        \"transaction_amount\": [100.00, 50.00, 75.00, 125.00, 200.00],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)\n",
    "try:\n",
    "    young_customers = df[df[\"age\"] < 35]\n",
    "except TypeError as e:\n",
    "    print(\"TypeError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure Consistent Data Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_data(base_date, n_normal=100, n_outliers=5, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    normal_dates = [\n",
    "        base_date + timedelta(days=int(x)) for x in np.random.normal(50, 10, n_normal)\n",
    "    ]\n",
    "    outlier_dates = [\n",
    "        base_date + timedelta(days=int(x)) for x in np.random.normal(50, 15, n_outliers)\n",
    "    ]\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": normal_dates + outlier_dates,\n",
    "            \"Amount\": np.concatenate(\n",
    "                [\n",
    "                    np.random.normal(100, 20, n_normal),\n",
    "                    np.random.normal(300, 30, n_outliers),\n",
    "                ]\n",
    "            ),\n",
    "            \"Type\": [\"Normal\"] * n_normal + [\"Suspicious\"] * n_outliers,\n",
    "        }\n",
    "    )\n",
    "    return data.sort_values(\"Date\")\n",
    "\n",
    "\n",
    "def plot_data(data):\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    # Plot normal transactions\n",
    "    normal_data = data[data['Type'] == 'Normal']\n",
    "    ax.scatter(\n",
    "        normal_data['Date'],\n",
    "        normal_data['Amount'],\n",
    "        c='#72BEFA',\n",
    "        marker='o',\n",
    "        s=80,\n",
    "        edgecolor='black',\n",
    "        linewidth=1,\n",
    "        label='Normal'\n",
    "    )\n",
    "    \n",
    "    # Plot suspicious transactions\n",
    "    suspicious_data = data[data['Type'] == 'Suspicious']\n",
    "    ax.scatter(\n",
    "        suspicious_data['Date'],\n",
    "        suspicious_data['Amount'],\n",
    "        c='#E583B6',\n",
    "        marker='*',\n",
    "        s=80,\n",
    "        edgecolor='black',\n",
    "        linewidth=1,\n",
    "        label='Suspicious'\n",
    "    )\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel(\"Date\", fontsize=12)\n",
    "    ax.set_ylabel(\"Transaction Amount ($)\", fontsize=12)\n",
    "    ax.set_title(\"Transaction Distribution with Outliers\", fontsize=14, pad=20)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "data = generate_data(base_date)\n",
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Freshness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define timeline data\n",
    "timeline = [\"2019-Q4\", \"2020-Q1\", \"2020-Q2\", \"2020-Q3\", \"2020-Q4\", \"2021-Q1\"]\n",
    "real_data = [28, 33, 85, 75, 70, 65]  # Actual online shopping data\n",
    "forecast_data = [28, 32, 35, 33, 30, 35]  # Forecast based on old patterns\n",
    "stale_data = [22, 24, 23, 25, 24, 26]  # Historical stale data\n",
    "\n",
    "plt.figure(figsize=(10, 4)) \n",
    "\n",
    "# Plot lines\n",
    "plt.plot(\n",
    "    timeline,\n",
    "    real_data,\n",
    "    color=\"#E583B6\",\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    label=\"Real Online Shopping Data\",\n",
    ")\n",
    "plt.plot(\n",
    "    timeline,\n",
    "    forecast_data,\n",
    "    color=\"#72BEFA\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Forecasted Pattern (Pre-Pandemic)\",\n",
    ")\n",
    "plt.plot(\n",
    "    timeline,\n",
    "    stale_data,\n",
    "    color=\"gray\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\":\",\n",
    "    alpha=0.5,\n",
    "    label=\"Historical Stale Data\",\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"Real vs Forecasted Online Shopping Trends\", pad=20)\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"Online Shopping Share (%)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Highlight forecast gap\n",
    "plt.fill_between(\n",
    "    timeline,\n",
    "    real_data,\n",
    "    forecast_data,\n",
    "    where=(np.array(real_data) > np.array(forecast_data)),\n",
    "    color=\"#E583B6\",\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data with missing values (represented as NaN)\n",
    "regions = [\"North\", \"South\", \"East\", \"West\", \"Central\"]\n",
    "sales = [150000, np.nan, 120000, np.nan, 180000]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "# Create bar chart\n",
    "bars = plt.bar(\n",
    "    regions,\n",
    "    sales,\n",
    "    color=[\"#E583B6\" if not np.isnan(x) else \"#72BEFA\" for x in sales],\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Customize the chart\n",
    "plt.title(\"Regional Sales Data with Missing Values\", pad=20)\n",
    "plt.xlabel(\"Regions\")\n",
    "plt.ylabel(\"Sales ($)\")\n",
    "plt.ylim(0, 195000)\n",
    "\n",
    "# Add text annotations\n",
    "for i, v in enumerate(sales):\n",
    "    if not np.isnan(v):\n",
    "        plt.text(i, v + 5000, f\"${int(v):,}\", ha=\"center\")\n",
    "    else:\n",
    "        plt.text(i, 10000, \"Missing Data\", ha=\"center\")\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "total_records = 10000\n",
    "duplicates = 800\n",
    "unique_customers = total_records - duplicates\n",
    "churned_customers = 1500\n",
    "\n",
    "# Calculate churn rates\n",
    "apparent_churn_rate = (churned_customers / total_records) * 100\n",
    "actual_churn_rate = (churned_customers / unique_customers) * 100\n",
    "\n",
    "# Create stacked bar data\n",
    "labels = [\"With Duplicates\", \"Without Duplicates\"]\n",
    "active_customers = [\n",
    "    total_records - churned_customers,\n",
    "    unique_customers - churned_customers,\n",
    "]\n",
    "churned = [churned_customers, churned_customers]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "# Split the left bar into non-duplicate and duplicate portions\n",
    "plt.bar(\n",
    "    labels[0],\n",
    "    unique_customers - churned_customers,\n",
    "    color=\"#72BEFA\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.bar(\n",
    "    labels[0],\n",
    "    duplicates,\n",
    "    bottom=unique_customers - churned_customers,\n",
    "    color=\"#A5D7FC\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.bar(labels[1], active_customers[1], color=\"#72BEFA\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "# Add the churned customers bars\n",
    "plt.bar(\n",
    "    labels,\n",
    "    churned,\n",
    "    bottom=active_customers,\n",
    "    color=\"#E583B6\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "# Add value labels on the bars\n",
    "for i in range(len(labels)):\n",
    "    # Label for active customers\n",
    "    plt.text(\n",
    "        i,\n",
    "        (unique_customers - churned_customers) / 2,\n",
    "        (\n",
    "            f\"Active: {unique_customers - churned_customers:,}\"\n",
    "            if i == 0\n",
    "            else f\"Active: {active_customers[1]:,}\"\n",
    "        ),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "    # Add annotation for duplicate portion (only for left bar)\n",
    "    if i == 0:\n",
    "        plt.text(\n",
    "            i,\n",
    "            unique_customers - churned_customers + duplicates / 2,\n",
    "            f\"Active Duplicates: {duplicates:,}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    # Label for churned customers with percentage\n",
    "    plt.text(\n",
    "        i,\n",
    "        active_customers[i] + churned[i] / 2,\n",
    "        (\n",
    "            f\"Churned: {churned[i]:,}\\n({apparent_churn_rate:.1f}%)\"\n",
    "            if i == 0\n",
    "            else f\"Churned: {churned[i]:,}\\n({actual_churn_rate:.1f}%)\"\n",
    "        ),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "    # Label for total\n",
    "    plt.text(\n",
    "        i,\n",
    "        active_customers[i] + churned[i] + 100,\n",
    "        f\"Total: {active_customers[i] + churned[i]:,}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# Customize chart\n",
    "plt.title(\"Customer Distribution: With vs Without Duplicates\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.ylim(0, max(total_records, unique_customers) * 1.1)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Generate data\n",
    "def generate_data():\n",
    "    # True underlying trend (e.g., market trend)\n",
    "    x_full = np.linspace(0, 10, 100)\n",
    "    y_full = 2 * np.sin(x_full) + 0.5 * x_full\n",
    "\n",
    "    # Small dataset (limited historical data)\n",
    "    x_small = np.linspace(0, 10, 5)\n",
    "    y_small = (\n",
    "        2 * np.sin(x_small)\n",
    "        + 0.5 * x_small\n",
    "        + np.random.normal(scale=0.5, size=len(x_small))\n",
    "    )\n",
    "\n",
    "    # Larger dataset (more historical data)\n",
    "    x_large = np.linspace(0, 10, 50)\n",
    "    y_large = (\n",
    "        2 * np.sin(x_large)\n",
    "        + 0.5 * x_large\n",
    "        + np.random.normal(scale=0.5, size=len(x_large))\n",
    "    )\n",
    "\n",
    "    return x_full, y_full, x_small, y_small, x_large, y_large\n",
    "\n",
    "\n",
    "# Plot data\n",
    "def plot_data(x_full, y_full, x_small, y_small, x_large, y_large):\n",
    "    # Plot true underlying trend\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(x_full, y_full, color=\"#2F2D2E\", label=\"True Market Trend\", linewidth=2)\n",
    "\n",
    "    # Plot forecast from small dataset\n",
    "    z_small = np.polyfit(x_small, y_small, 4)  # Fit a polynomial of degree 4\n",
    "    y_forecast_small = np.polyval(z_small, x_full)\n",
    "    plt.plot(\n",
    "        x_full,\n",
    "        y_forecast_small,\n",
    "        \"--\",\n",
    "        color=\"#E583B6\",\n",
    "        label=\"Forecast (Small Dataset)\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        x_small,\n",
    "        y_small,\n",
    "        color=\"#E583B6\",\n",
    "        label=\"Historical Data (Small)\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "\n",
    "    # Plot forecast from large dataset\n",
    "    z_large = np.polyfit(x_large, y_large, 4)  # Fit a polynomial of degree 4\n",
    "    y_forecast_large = np.polyval(z_large, x_full)\n",
    "    plt.plot(\n",
    "        x_full,\n",
    "        y_forecast_large,\n",
    "        \"-\",\n",
    "        color=\"#72BEFA\",\n",
    "        label=\"Forecast (Large Dataset)\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.scatter(\n",
    "        x_large,\n",
    "        y_large,\n",
    "        color=\"#72BEFA\",\n",
    "        label=\"Historical Data (Large)\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    # Configure plot\n",
    "    plt.title(\"Market Trend Forecasting\", fontsize=14)\n",
    "    plt.xlabel(\"Time\", fontsize=12)\n",
    "    plt.ylabel(\"Market Value\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Main\n",
    "x_full, y_full, x_small, y_small, x_large, y_large = generate_data()\n",
    "plot_data(x_full, y_full, x_small, y_small, x_large, y_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Made Easy with Pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample data with mixed age types\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"customer_id\": [1, 2, 3, 4, 5],\n",
    "\t\t\"age\": [25, 30, 35, 40, 45],\n",
    "\t\t\"transaction_amount\": [100.0, 50.0, 75.0, 125.0, 200.0],\n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "# Define the schema\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"customer_id\": pa.Column(\n",
    "\t\t\tint, checks=pa.Check.ge(1), unique=True\n",
    "\t\t),  # <1>\n",
    "\t\t\"age\": pa.Column(\n",
    "\t\t\tint, checks=pa.Check.between(0, 120)\n",
    "\t\t),  # <2>\n",
    "\t\t\"transaction_amount\": pa.Column(\n",
    "\t\t\tfloat, checks=pa.Check.ge(0)\n",
    "\t\t),  # <3>\n",
    "\t}\n",
    ")\n",
    "# Validate the DataFrame\n",
    "validated_df = schema.validate(df)  # <4>\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of validation failure\n",
    "invalid_df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [1, 2, 2, 4, 5],  # Duplicate ID\n",
    "        \"age\": [25, 150, -5, 40, 45],  # Invalid ages\n",
    "        \"transaction_amount\": [100.00, 50.00, 75.00, 125.00, 200.00],\n",
    "    }\n",
    ")\n",
    "\n",
    "# This will raise SchemaError\n",
    "try:\n",
    "    schema.validate(invalid_df)\n",
    "except pa.errors.SchemaError as err:\n",
    "    print('SchemaError:', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_even = pa.Check(lambda s: s % 2 == 0)\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\"column1\": pa.Column(int, check_is_even)}\n",
    ")\n",
    "schema.validate(pd.DataFrame({\"column1\": [2, 4, 6, 8]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "customer_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": pa.Column(\n",
    "            str, checks=pa.Check.str_length(min_value=5)\n",
    "        ),\n",
    "        \"email\": pa.Column(str, checks=pa.Check.str_contains(\"@\")),\n",
    "        \"signup_date\": pa.Column(\n",
    "            datetime, checks=pa.Check.le(datetime.now())\n",
    "        ),  # Date not in future\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [\"CUST01\", \"CUST02\", \"CUST03\"],\n",
    "        \"email\": [\"john@mail.com\", \"jane@mail.com\", \"bob@mail.com\"],\n",
    "        \"signup_date\": [\"2023-01-01\", \"2023-02-15\", \"2023-03-30\"],\n",
    "    }\n",
    ")\n",
    "customer[\"signup_date\"] = pd.to_datetime(customer[\"signup_date\"])\n",
    "\n",
    "# Validate data\n",
    "validated_df = customer_schema.validate(customer)\n",
    "print(\"Validation passed!\")\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Check Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"store\": [\"NY\", \"CA\", \"NY\", \"CA\"],\n",
    "\t\t\"profit\": [200.0, 300.0, 300.0, 400.0],\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Define schema with wide check using groupby\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"store\": pa.Column(str),\n",
    "\t\t\"profit\": pa.Column(\n",
    "\t\t\tfloat,\n",
    "\t\t\t# Check CA stores have higher average profit than NY\n",
    "\t\t\tpa.Check(\n",
    "\t\t\t\tlambda g: g[\"CA\"].mean() > g[\"NY\"].mean(),\n",
    "\t\t\t\tgroupby=\"store\",\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Validate the DataFrame\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wide Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "df = pd.DataFrame({\n",
    "    \"revenue\": [1000.0, 1500.0, 1200.0],\n",
    "    \"expenses\": [800.0, 1200.0, 900.0],\n",
    "    \"profit\": [200.0, 300.0, 300.0],\n",
    "})\n",
    "\n",
    "# Define schema with wide check\n",
    "schema = pa.DataFrameSchema(\n",
    "    columns={\n",
    "        \"revenue\": pa.Column(float),\n",
    "        \"expenses\": pa.Column(float),\n",
    "        \"profit\": pa.Column(float),\n",
    "    },\n",
    "    checks=pa.Check(\n",
    "        lambda df: df[\"profit\"] == df[\"revenue\"] - df[\"expenses\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_input\n",
    "\n",
    "\n",
    "input_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": pa.Column(str),\n",
    "        \"age\": pa.Column(int, pa.Check.between(0, 120)),\n",
    "        \"score\": pa.Column(float, pa.Check.between(0, 100)),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(input_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "    data[\"grade\"] = pd.cut(\n",
    "        data[\"score\"],\n",
    "        bins=[0, 70, 80, 90, 100],\n",
    "        labels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "        include_lowest=True,\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"John\", \"Jane\", \"Bob\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"score\": [95.5, 88.3, 92.7],\n",
    "    }\n",
    ")\n",
    "result = calculate_grade(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_output\n",
    "\n",
    "output_schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"name\": pa.Column(str),\n",
    "\t\t\"age\": pa.Column(int, pa.Check.between(0, 120)),\n",
    "\t\t\"score\": pa.Column(float, pa.Check.between(0, 100)),\n",
    "\t\t\"grade\": pa.Column(\n",
    "\t\t\tstr, pa.Check(lambda x: x.isin([\"A\", \"B\", \"C\", \"F\"]))\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(input_schema)\n",
    "@check_output(output_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "\tdata[\"grade\"] = pd.cut(\n",
    "\t\tdata[\"score\"],\n",
    "\t\tbins=[0, 70, 80, 90, 100],\n",
    "\t\tlabels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "\t\tinclude_lowest=True,\n",
    "\t)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Both Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_io\n",
    "\n",
    "\n",
    "@check_io(data=input_schema, out=output_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "    data[\"grade\"] = pd.cut(\n",
    "        data[\"score\"],\n",
    "        bins=[0, 70, 80, 90, 100],\n",
    "        labels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "        include_lowest=True,\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"John\", \"Jane\", \"Bob\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"score\": [95.5, 88.3, 92.7],\n",
    "    }\n",
    ")\n",
    "result = calculate_grade(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Arguments for Column Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int),  # Does not allow nulls\n",
    "\t\t\"name\": pa.Column(str, nullable=True),  # Allows nulls\n",
    "\t\t\"age\": pa.Column(float, nullable=True),  # Allows nulls\n",
    "\t}\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"id\": [1, 2, 3],\n",
    "\t\t\"name\": [\"John\", None, \"Mary\"],\n",
    "\t\t\"age\": [25.0, 30.0, None],\n",
    "\t}\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema with unique constraint\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int, unique=True),  # Must be unique\n",
    "\t\t\"name\": pa.Column(str),  # Duplicates allowed\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\"id\": [1, 1, 2], \"name\": [\"John\", \"Jane\", \"Mary\"]}\n",
    ")\n",
    "\n",
    "try:\n",
    "\tvalidated_df = schema.validate(df)\n",
    "except pa.errors.SchemaError as e:\n",
    "\tprint(\"SchemaError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Required Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema with required columns\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int),  # Required column\n",
    "\t\t\"name\": pa.Column(str),  # Required column\n",
    "\t\t\"age\": pa.Column(int, required=False),  # Optional column\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Mary\"]}\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Match Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema using regex to match column patterns\n",
    "schema = pa.DataFrameSchema({\n",
    "    # Match any column starting with 'score_'\n",
    "    'score_.*': pa.Column(float, regex=True, nullable=True),\n",
    "    # Regular columns without regex\n",
    "    'student_id': pa.Column(int),\n",
    "    'name': pa.Column(str)\n",
    "})\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'student_id': [1, 2, 3],\n",
    "    'name': ['John', 'Mary', 'Bob'],\n",
    "    'score_math': [85.5, 90.0, None],\n",
    "    'score_science': [88.0, None, 92.5],\n",
    "    'score_history': [78.5, 88.5, 95.0],\n",
    "})\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import Series, DataFrame\n",
    "import hashlib\n",
    "\n",
    "\n",
    "class CustomerSchema(pa.DataFrameModel):\n",
    "\tcustomer_id: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 5, \"max_value\": 10}\n",
    "\t)\n",
    "\temail: Series[str] = pa.Field(str_contains=\"@\")\n",
    "\n",
    "\n",
    "class AnonymizedCustomerSchema(pa.DataFrameModel):\n",
    "\tcustomer_id: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 5, \"max_value\": 10}\n",
    "\t)\n",
    "\tanonymized_email: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 32, \"max_value\": 32}\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data at the Point of Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sales_data(sales_df: pd.DataFrame) -> dict:\n",
    "\t# Problems only discovered during processing\n",
    "\trevenue = sales_df[\"price\"] * sales_df[\"quantity\"]\n",
    "\n",
    "\treturn {\n",
    "\t\t\"total_revenue\": revenue.sum(),\n",
    "\t\t\"max_sale\": sales_df[\"quantity\"].max(),\n",
    "\t}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# Data with issues\n",
    "\tdata = pd.DataFrame(\n",
    "\t\t{\n",
    "\t\t\t\"price\": [50, 100, \"invalid\", 75],\n",
    "\t\t\t\"quantity\": [5, 3, 2, \"error\"],\n",
    "\t\t}\n",
    "\t)\n",
    "\ttry:\n",
    "\t\tresults = analyze_sales_data(data)\n",
    "\t\tprint(results)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for sales DataFrame\n",
    "sales_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"price\": pa.Column(float, checks=[pa.Check.ge(0)]),\n",
    "        \"quantity\": pa.Column(int, checks=[pa.Check.ge(0)]),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(sales_schema)\n",
    "def analyze_sales_data(sales_df: pd.DataFrame) -> dict:\n",
    "    revenue = sales_df[\"price\"] * sales_df[\"quantity\"]\n",
    "\n",
    "    return {\n",
    "        \"total_revenue\": revenue.sum(),\n",
    "        \"max_sale\": sales_df[\"quantity\"].max(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Only Critical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only validate columns used in the calculation\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"amount\": pa.Column(float, checks=pa.Check.gt(0)),\n",
    "\t\t\"store\": pa.Column(\n",
    "\t\t\tstr, checks=pa.Check.isin([\"A\", \"B\"])\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "@pa.check_input(schema)\n",
    "def get_amount_by_store(df):\n",
    "\treturn df.groupby(\"store\")[\"amount\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"customer_id\": [1, 2, 3],\n",
    "\t\t\"amount\": [100.0, 200.0, 300.0],\n",
    "\t\t\"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n",
    "\t\t\"store\": [\"A\", \"B\", \"A\"],\n",
    "\t}\n",
    ")\n",
    "amount_by_store = get_amount_by_store(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}