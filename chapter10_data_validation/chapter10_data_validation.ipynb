{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Data Validation Made Easy with Pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Basic Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample data with mixed age types\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"customer_id\": [1, 2, 3, 4, 5],\n",
    "\t\t\"age\": [25, 30, 35, 40, 45],\n",
    "\t\t\"transaction_amount\": [100.0, 50.0, 75.0, 125.0, 200.0],\n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "# Define the schema\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"customer_id\": pa.Column(\n",
    "\t\t\tint, checks=pa.Check.ge(1), unique=True\n",
    "\t\t),  # <1>\n",
    "\t\t\"age\": pa.Column(\n",
    "\t\t\tint, checks=pa.Check.between(0, 120)\n",
    "\t\t),  # <2>\n",
    "\t\t\"transaction_amount\": pa.Column(\n",
    "\t\t\tfloat, checks=pa.Check.ge(0)\n",
    "\t\t),  # <3>\n",
    "\t}\n",
    ")\n",
    "# Validate the DataFrame\n",
    "validated_df = schema.validate(df)  # <4>\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of validation failure\n",
    "invalid_df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [1, 2, 2, 4, 5],  # Duplicate ID\n",
    "        \"age\": [25, 150, -5, 40, 45],  # Invalid ages\n",
    "        \"transaction_amount\": [100.00, 50.00, 75.00, 125.00, 200.00],\n",
    "    }\n",
    ")\n",
    "\n",
    "# This will raise SchemaError\n",
    "try:\n",
    "    schema.validate(invalid_df)\n",
    "except pa.errors.SchemaError as err:\n",
    "    print('SchemaError:', err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_even = pa.Check(lambda s: s % 2 == 0)\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\"column1\": pa.Column(int, check_is_even)}\n",
    ")\n",
    "schema.validate(pd.DataFrame({\"column1\": [2, 4, 6, 8]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "#### Built-in Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "customer_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": pa.Column(\n",
    "            str, checks=pa.Check.str_length(min_value=5)\n",
    "        ),\n",
    "        \"email\": pa.Column(str, checks=pa.Check.str_contains(\"@\")),\n",
    "        \"signup_date\": pa.Column(\n",
    "            datetime, checks=pa.Check.le(datetime.now())\n",
    "        ),  # Date not in future\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [\"CUST01\", \"CUST02\", \"CUST03\"],\n",
    "        \"email\": [\"john@mail.com\", \"jane@mail.com\", \"bob@mail.com\"],\n",
    "        \"signup_date\": [\"2023-01-01\", \"2023-02-15\", \"2023-03-30\"],\n",
    "    }\n",
    ")\n",
    "customer[\"signup_date\"] = pd.to_datetime(customer[\"signup_date\"])\n",
    "\n",
    "# Validate data\n",
    "validated_df = customer_schema.validate(customer)\n",
    "print(\"Validation passed!\")\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "#### Column Check Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"store\": [\"NY\", \"CA\", \"NY\", \"CA\"],\n",
    "\t\t\"profit\": [200.0, 300.0, 300.0, 400.0],\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Define schema with wide check using groupby\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"store\": pa.Column(str),\n",
    "\t\t\"profit\": pa.Column(\n",
    "\t\t\tfloat,\n",
    "\t\t\t# Check CA stores have higher average profit than NY\n",
    "\t\t\tpa.Check(\n",
    "\t\t\t\tlambda g: g[\"CA\"].mean() > g[\"NY\"].mean(),\n",
    "\t\t\t\tgroupby=\"store\",\n",
    "\t\t\t),\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Validate the DataFrame\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "#### Wide Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "df = pd.DataFrame({\n",
    "    \"revenue\": [1000.0, 1500.0, 1200.0],\n",
    "    \"expenses\": [800.0, 1200.0, 900.0],\n",
    "    \"profit\": [200.0, 300.0, 300.0],\n",
    "})\n",
    "\n",
    "# Define schema with wide check\n",
    "schema = pa.DataFrameSchema(\n",
    "    columns={\n",
    "        \"revenue\": pa.Column(float),\n",
    "        \"expenses\": pa.Column(float),\n",
    "        \"profit\": pa.Column(float),\n",
    "    },\n",
    "    checks=pa.Check(\n",
    "        lambda df: df[\"profit\"] == df[\"revenue\"] - df[\"expenses\"]\n",
    "    ),\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "### Validation Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "#### Check Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_input\n",
    "\n",
    "\n",
    "input_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": pa.Column(str),\n",
    "        \"age\": pa.Column(int, pa.Check.between(0, 120)),\n",
    "        \"score\": pa.Column(float, pa.Check.between(0, 100)),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(input_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "    data[\"grade\"] = pd.cut(\n",
    "        data[\"score\"],\n",
    "        bins=[0, 70, 80, 90, 100],\n",
    "        labels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "        include_lowest=True,\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"John\", \"Jane\", \"Bob\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"score\": [95.5, 88.3, 92.7],\n",
    "    }\n",
    ")\n",
    "result = calculate_grade(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "#### Check Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_output\n",
    "\n",
    "output_schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"name\": pa.Column(str),\n",
    "\t\t\"age\": pa.Column(int, pa.Check.between(0, 120)),\n",
    "\t\t\"score\": pa.Column(float, pa.Check.between(0, 100)),\n",
    "\t\t\"grade\": pa.Column(\n",
    "\t\t\tstr, pa.Check(lambda x: x.isin([\"A\", \"B\", \"C\", \"F\"]))\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(input_schema)\n",
    "@check_output(output_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "\tdata[\"grade\"] = pd.cut(\n",
    "\t\tdata[\"score\"],\n",
    "\t\tbins=[0, 70, 80, 90, 100],\n",
    "\t\tlabels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "\t\tinclude_lowest=True,\n",
    "\t)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "#### Check Both Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import check_io\n",
    "\n",
    "\n",
    "@check_io(data=input_schema, out=output_schema)\n",
    "def calculate_grade(data: pd.DataFrame):\n",
    "    data[\"grade\"] = pd.cut(\n",
    "        data[\"score\"],\n",
    "        bins=[0, 70, 80, 90, 100],\n",
    "        labels=[\"F\", \"C\", \"B\", \"A\"],\n",
    "        include_lowest=True,\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"John\", \"Jane\", \"Bob\"],\n",
    "        \"age\": [25, 30, 35],\n",
    "        \"score\": [95.5, 88.3, 92.7],\n",
    "    }\n",
    ")\n",
    "result = calculate_grade(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "### Other Arguments for Column Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "#### Deal with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int),  # Does not allow nulls\n",
    "\t\t\"name\": pa.Column(str, nullable=True),  # Allows nulls\n",
    "\t\t\"age\": pa.Column(float, nullable=True),  # Allows nulls\n",
    "\t}\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"id\": [1, 2, 3],\n",
    "\t\t\"name\": [\"John\", None, \"Mary\"],\n",
    "\t\t\"age\": [25.0, 30.0, None],\n",
    "\t}\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "#### Deal with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema with unique constraint\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int, unique=True),  # Must be unique\n",
    "\t\t\"name\": pa.Column(str),  # Duplicates allowed\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\"id\": [1, 1, 2], \"name\": [\"John\", \"Jane\", \"Mary\"]}\n",
    ")\n",
    "\n",
    "try:\n",
    "\tvalidated_df = schema.validate(df)\n",
    "except pa.errors.SchemaError as e:\n",
    "\tprint(\"SchemaError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "##### Required Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema with required columns\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"id\": pa.Column(int),  # Required column\n",
    "\t\t\"name\": pa.Column(str),  # Required column\n",
    "\t\t\"age\": pa.Column(int, required=False),  # Optional column\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "\t{\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Mary\"]}\n",
    ")\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "#### Match Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema using regex to match column patterns\n",
    "schema = pa.DataFrameSchema({\n",
    "    # Match any column starting with 'score_'\n",
    "    'score_.*': pa.Column(float, regex=True, nullable=True),\n",
    "    # Regular columns without regex\n",
    "    'student_id': pa.Column(int),\n",
    "    'name': pa.Column(str)\n",
    "})\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'student_id': [1, 2, 3],\n",
    "    'name': ['John', 'Mary', 'Bob'],\n",
    "    'score_math': [85.5, 90.0, None],\n",
    "    'score_science': [88.0, None, 92.5],\n",
    "    'score_history': [78.5, 88.5, 95.0],\n",
    "})\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(\"Validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### Schema Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import Series, DataFrame\n",
    "import hashlib\n",
    "\n",
    "\n",
    "class CustomerSchema(pa.DataFrameModel):\n",
    "\tcustomer_id: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 5, \"max_value\": 10}\n",
    "\t)\n",
    "\temail: Series[str] = pa.Field(str_contains=\"@\")\n",
    "\n",
    "\n",
    "class AnonymizedCustomerSchema(pa.DataFrameModel):\n",
    "\tcustomer_id: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 5, \"max_value\": 10}\n",
    "\t)\n",
    "\tanonymized_email: Series[str] = pa.Field(\n",
    "\t\tstr_length={\"min_value\": 32, \"max_value\": 32}\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "### Export and Load From a YAML File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-51",
   "metadata": {},
   "source": [
    "#### Export to YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the schema (reusing our existing schema)\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": pa.Column(\n",
    "            int, checks=pa.Check.ge(1), unique=True\n",
    "        ),\n",
    "        \"age\": pa.Column(\n",
    "            int, checks=pa.Check.between(0, 120)\n",
    "        ),\n",
    "        \"transaction_amount\": pa.Column(\n",
    "            float, checks=pa.Check.ge(0)\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Export schema to YAML\n",
    "yaml_schema = schema.to_yaml()\n",
    "print(\"Exported YAML schema:\")\n",
    "print(yaml_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save schema to a YAML file for team sharing\n",
    "schema_file = Path(\"customer_schema.yml\")\n",
    "\n",
    "# Write YAML schema to file\n",
    "with schema_file.open(\"w\") as f:\n",
    "    f.write(yaml_schema)\n",
    "\n",
    "print(f\"Schema saved to {schema_file}\")\n",
    "print(f\"File exists: {schema_file.exists()}\")\n",
    "print(f\"File size: {schema_file.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load schema from YAML file\n",
    "with schema_file.open(\"r\") as f:\n",
    "    yaml_content = f.read()\n",
    "\n",
    "# Import the schema from YAML\n",
    "import pandera as pa\n",
    "loaded_schema = pa.io.from_yaml(yaml_content)\n",
    "\n",
    "print(\"Schema loaded successfully from YAML!\")\n",
    "print(f\"Schema type: {type(loaded_schema)}\")\n",
    "print(f\"Schema columns: {list(loaded_schema.columns.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data using the imported schema\n",
    "# Using our original data from earlier examples\n",
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [1, 2, 3, 4, 5],\n",
    "        \"age\": [25, 30, 35, 40, 45],\n",
    "        \"transaction_amount\": [100.0, 50.0, 75.0, 125.0, 200.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Testing loaded schema with valid data:\")\n",
    "validated_df = loaded_schema.validate(test_df)\n",
    "print(\"✓ Validation successful!\")\n",
    "print(validated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with invalid data to confirm the loaded schema works properly\n",
    "invalid_test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": [1, 2, 2, 4, 5],  # Duplicate ID\n",
    "        \"age\": [25, 150, -5, 40, 45],  # Invalid ages\n",
    "        \"transaction_amount\": [100.0, 50.0, 75.0, 125.0, 200.0],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Testing loaded schema with invalid data:\")\n",
    "try:\n",
    "    loaded_schema.validate(invalid_test_df)\n",
    "    print(\"This should not print\")\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(\"✓ Schema correctly caught validation errors:\")\n",
    "    print(f\"  Error: {str(e)[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-64",
   "metadata": {},
   "source": [
    "## Best Practices for Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-65",
   "metadata": {},
   "source": [
    "### Validate Data at the Point of Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sales_data(sales_df: pd.DataFrame) -> dict:\n",
    "\t# Problems only discovered during processing\n",
    "\trevenue = sales_df[\"price\"] * sales_df[\"quantity\"]\n",
    "\n",
    "\treturn {\n",
    "\t\t\"total_revenue\": revenue.sum(),\n",
    "\t\t\"max_sale\": sales_df[\"quantity\"].max(),\n",
    "\t}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# Data with issues\n",
    "\tdata = pd.DataFrame(\n",
    "\t\t{\n",
    "\t\t\t\"price\": [50, 100, \"invalid\", 75],\n",
    "\t\t\t\"quantity\": [5, 3, 2, \"error\"],\n",
    "\t\t}\n",
    "\t)\n",
    "\ttry:\n",
    "\t\tresults = analyze_sales_data(data)\n",
    "\t\tprint(results)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for sales DataFrame\n",
    "sales_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"price\": pa.Column(float, checks=[pa.Check.ge(0)]),\n",
    "        \"quantity\": pa.Column(int, checks=[pa.Check.ge(0)]),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "@check_input(sales_schema)\n",
    "def analyze_sales_data(sales_df: pd.DataFrame) -> dict:\n",
    "    revenue = sales_df[\"price\"] * sales_df[\"quantity\"]\n",
    "\n",
    "    return {\n",
    "        \"total_revenue\": revenue.sum(),\n",
    "        \"max_sale\": sales_df[\"quantity\"].max(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-68",
   "metadata": {},
   "source": [
    "### Validate Only Critical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only validate columns used in the calculation\n",
    "schema = pa.DataFrameSchema(\n",
    "\t{\n",
    "\t\t\"amount\": pa.Column(float, checks=pa.Check.gt(0)),\n",
    "\t\t\"store\": pa.Column(\n",
    "\t\t\tstr, checks=pa.Check.isin([\"A\", \"B\"])\n",
    "\t\t),\n",
    "\t}\n",
    ")\n",
    "\n",
    "\n",
    "@pa.check_input(schema)\n",
    "def get_amount_by_store(df):\n",
    "\treturn df.groupby(\"store\")[\"amount\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "\t{\n",
    "\t\t\"customer_id\": [1, 2, 3],\n",
    "\t\t\"amount\": [100.0, 200.0, 300.0],\n",
    "\t\t\"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n",
    "\t\t\"store\": [\"A\", \"B\", \"A\"],\n",
    "\t}\n",
    ")\n",
    "amount_by_store = get_amount_by_store(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
