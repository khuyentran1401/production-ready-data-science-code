{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Python Functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IceCream:\n",
    "\tdef __init__(self, flavor: str):\n",
    "\t\tself.flavor = flavor\n",
    "\n",
    "\tdef eat(self):\n",
    "\t\tprint(\n",
    "\t\t\tf\"Eating the {self.flavor} ice cream\"\n",
    "\t\t)\n",
    "\n",
    "\n",
    "chocolate = IceCream(\"chocolate\")\n",
    "vanilla = IceCream(\"vanilla\")\n",
    "\n",
    "chocolate.eat()\n",
    "vanilla.eat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Are Python Functions Essential?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([5, 10, 15, 20, 25])\n",
    "X_test = np.array([8, 12, 18, 22, 28])\n",
    "\n",
    "X_train_standardized = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_standardized = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "X_train = np.array([5, 10, 15, 20, 25])\n",
    "X_test = np.array([8, 12, 18, 22, 28])\n",
    "\n",
    "X_train_standardized = standardize_features(X_train)\n",
    "X_test_standardized = standardize_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Code Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"category\": [\"A\", \"B\", \"C\"],\n",
    "        \"feature1\": [10.5, 15.2, 7.8],\n",
    "        \"feature2\": [100, 150, 80],\n",
    "        \"target\": [5.5, 8.2, 6.7],\n",
    "    }\n",
    ")\n",
    "\n",
    "data.to_csv(\"data/dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load the data from a CSV file\n",
    "data = pd.read_csv(\"data/dataset.csv\")\n",
    "\n",
    "# Handle missing values by filling them with 0\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Encode the categorical variable 'category'\n",
    "data[\"category\"] = data[\"category\"].map(\n",
    "    {\"A\": 0, \"B\": 1, \"C\": 2}\n",
    ")\n",
    "\n",
    "# Using the StandardScaler to standardize the data\n",
    "scaler = StandardScaler()\n",
    "data[\"feature1\"] = scaler.fit_transform(\n",
    "    data[\"feature1\"].values.reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hide Implementation Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('data/users.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"DROP TABLE IF EXISTS users\");\n",
    "\n",
    "# Create the users table\n",
    "cursor.execute('''\n",
    "CREATE TABLE users (\n",
    "    username TEXT NOT NULL,\n",
    "    email TEXT NOT NULL\n",
    ")\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def save_user(username, email):\n",
    "    with sqlite3.connect(\"data/users.db\") as conn:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO users (username, email) VALUES (?, ?)\",\n",
    "                (username, email),\n",
    "            )\n",
    "            conn.commit()\n",
    "            print(\"User saved successfully\")\n",
    "        except sqlite3.Error:\n",
    "            print(\"Failed to save user\")\n",
    "\n",
    "# Users can call this function without understanding database details\n",
    "save_user(\"john_doe\", \"john@example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Python Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Descriptive Verb-Based Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(df):\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def transform(s):\n",
    "    return np.log(s)\n",
    "\n",
    "\n",
    "def above_mean(df, column):\n",
    "    return df[df[column] > df[column].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_values(df):\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def apply_log_transformation(s):\n",
    "    return np.log(s)\n",
    "\n",
    "\n",
    "def filter_values_above_mean(df, column):\n",
    "    return df[df[column] > df[column].mean()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Functions Focused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Sales': [1000, 1500, 800],\n",
    "    'Quantity': [10, 15, 8],\n",
    "    'Category': ['Electronics', 'Clothing', 'Books'],\n",
    "    'Region': ['North', 'South', 'East']\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "data.to_csv('data/sales_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def process_sales_data(df):\n",
    "    # Remove missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Log transform sales\n",
    "    df[\"log_sales\"] = np.log1p(df[\"Sales\"])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=[\"Category\", \"Region\"])\n",
    "\n",
    "    # Normalize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    num_columns = [\"Sales\", \"Quantity\"]\n",
    "    df[num_columns] = scaler.fit_transform(df[num_columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_values(df):\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def log_transform_sales(df):\n",
    "    return df.assign(\n",
    "        log_sales=lambda x: np.log1p(x[\"Sales\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def encode_categorical_variables(df, cat_columns):\n",
    "    return pd.get_dummies(df, columns=cat_columns)\n",
    "\n",
    "\n",
    "def normalize_numeric_features(df, num_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df = df.copy()\n",
    "    df[num_columns] = scaler.fit_transform(df[num_columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sales_data(df):\n",
    "    return (\n",
    "        df.pipe(remove_missing_values)\n",
    "        .pipe(log_transform_sales)\n",
    "        .pipe(\n",
    "            encode_categorical_variables,\n",
    "            cat_columns=[\"Category\", \"Region\"],\n",
    "        )\n",
    "        .pipe(\n",
    "            normalize_numeric_features,\n",
    "            num_columns=[\"Sales\", \"Quantity\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Type Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_rating(ratings, product_id):\n",
    "    product_ratings = [\n",
    "        r for r in ratings if r[\"product_id\"] == product_id\n",
    "    ]\n",
    "    if not product_ratings:\n",
    "        return None\n",
    "    total_score = sum(r[\"score\"] for r in product_ratings)\n",
    "    return total_score / len(product_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_rating(\n",
    "    ratings: list[dict[str, int]], product_id: int\n",
    ") -> float | None:\n",
    "\n",
    "   ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Clear and Helpful Docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pipe_delimited_text(text: str) -> dict:\n",
    "    parts = text.split(\"|\")\n",
    "    if len(parts) % 2 != 0:\n",
    "        raise ValueError(\n",
    "            \"Input string must have an even number of parts\"\n",
    "        )\n",
    "    return {parts[i]: parts[i + 1] for i in range(0, len(parts), 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pipe_delimited_text(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a pipe-delimited string into a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        A pipe-delimited string to parse\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with even indices as keys, odd indices as values\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError: If the input string has an odd number of parts\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> parse_pipe_delimited_text(\"name|John|age|30\")\n",
    "    {'name': 'John', 'age': '30'}\n",
    "    \"\"\"\n",
    "    parts = text.split(\"|\")\n",
    "    if len(parts) % 2 != 0:\n",
    "        raise ValueError(\n",
    "            \"Input string must have an even number of parts\"\n",
    "        )\n",
    "    return {parts[i]: parts[i + 1] for i in range(0, len(parts), 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Function Parameters Instead of Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "train_labels = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "def cv_rmse(model, X):\n",
    "    return np.sqrt(\n",
    "        -cross_val_score(\n",
    "            model, X, train_labels,\n",
    "            scoring=\"neg_mean_squared_error\", cv=kf\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Calculate RMSE scores\n",
    "scores = cv_rmse(model=model, X=X)\n",
    "print(f\"Mean RMSE: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the global variable\n",
    "kf = KFold(n_splits=2, random_state=42, shuffle=True)\n",
    "\n",
    "# The function's output will change\n",
    "scores = cv_rmse(model=model, X=X)\n",
    "print(f\"Mean RMSE: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_rmse(model, X, train_labels, kf):\n",
    "    rmse = np.sqrt(\n",
    "        -cross_val_score(\n",
    "            model, X, train_labels,\n",
    "            scoring=\"neg_mean_squared_error\", cv=kf\n",
    "        )\n",
    "    )\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Modifying Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df[columns] = (\n",
    "        df[columns] - df[columns].mean()\n",
    "    ) / df[columns].std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"temperature\": [25.5, 27.8, 23.2],\n",
    "        \"humidity\": [60.0, 55.5, 62.3],\n",
    "        \"pressure\": [1013.2, 1015.7, 1012.8],\n",
    "    }\n",
    ")\n",
    "\n",
    "normalized_data = normalize_data(data, columns=[\"humidity\"])\n",
    "print(f\"Original data:\\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[columns] = (\n",
    "        df[columns] - df[columns].mean()\n",
    "    ) / df[columns].std()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"temperature\": [25.5, 27.8, 23.2],\n",
    "        \"humidity\": [60.0, 55.5, 62.3],\n",
    "        \"pressure\": [1013.2, 1015.7, 1012.8],\n",
    "    }\n",
    ")\n",
    "normalized_data = normalize_data(data, columns=[\"humidity\"])\n",
    "print(f\"Original data:\\n{data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Using Flags As Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\"A\": [1, 2, np.nan], \"B\": [10, 20, 30], \"C\": [100, 200, 300]})\n",
    "\n",
    "df.to_csv(\"data/sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    df: pd.DataFrame,\n",
    "    fill_missing: bool = False,\n",
    "    normalize: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    if fill_missing:\n",
    "        df = df.fillna(df.mean())\n",
    "\n",
    "    if normalize:\n",
    "        df = (df - df.mean()) / df.std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sample.csv\")\n",
    "cleaned_df = preprocess_data(df, fill_missing=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.fillna(df.mean())\n",
    "\n",
    "def normalize_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, steps: list) -> pd.DataFrame:\n",
    "    for step in steps:\n",
    "        df = step(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sample.csv\")\n",
    "cleaning_steps = [normalize_data, fill_missing_values]\n",
    "cleaned_df = preprocess_data(df, cleaning_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Common Logic Into Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": [\n",
    "            \"Hello, World! 123\",\n",
    "            \"This is a TEST comment.\",\n",
    "            \"Special @#$% characters here!\",\n",
    "        ],\n",
    "        \"user\": [\"user1\", \"user2\", \"user3\"],\n",
    "        \"date\": [\"2023-05-01\", \"2023-05-02\", \"2023-05-03\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"data/comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"text\"] = df[\"text\"].str.lower()\n",
    "    df[\"text\"] = df[\"text\"].str.replace(\n",
    "        \"[^a-zA-Z\\s]\", \"\", regex=True\n",
    "    )\n",
    "    df[\"text\"] = df[\"text\"].str.strip()\n",
    "    return df\n",
    "\n",
    "def preprocess_user_input(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = \"\".join(\n",
    "        char for char in text if char.isalnum() or char.isspace()\n",
    "    )\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/comments.csv\")\n",
    "cleaned_df = clean_text_data(df)\n",
    "user_input = \"Hello, World! 123\"\n",
    "cleaned_input = preprocess_user_input(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = \"\".join(\n",
    "        char for char in text if char.isalnum() or char.isspace()\n",
    "    )\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_text_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_user_input(text: str) -> str:\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Function Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "squared = list(map(lambda x: x**2, numbers))\n",
    "print(squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Alice', 25), ('Bob', 30), ('Charlie', 22)]\n",
    "sorted_data = sorted(data, key=lambda x: x[1])\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def cv_rmse(model, X, train_labels, kf):\n",
    "    return np.sqrt(\n",
    "        -cross_val_score(\n",
    "            model, X, train_labels,\n",
    "            scoring=\"neg_mean_squared_error\", cv=kf\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Create sample data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "train_labels = np.array([2, 4, 5, 4, 5])\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Create a partial function with fixed X, train_labels, and kf\n",
    "cv_rmse_with_data = partial(\n",
    "    cv_rmse, X=X, train_labels=train_labels, kf=kf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the partial function with Linear Regression\n",
    "linear_scores = cv_rmse_with_data(model=LinearRegression())\n",
    "\n",
    "# Call the partial function with Ridge Regression\n",
    "ridge_scores = cv_rmse_with_data(model=Ridge(alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `*args` and `**kwargs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def transform_pipeline(\n",
    "    data: np.ndarray, *transformers: Callable\n",
    ") -> np.ndarray:\n",
    "    for transformer in transformers:\n",
    "        data = transformer(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(data: np.ndarray) -> np.ndarray:\n",
    "\treturn np.log1p(data)\n",
    "\n",
    "\n",
    "def standardize(data: np.ndarray) -> np.ndarray:\n",
    "\treturn (data - data.mean()) / data.std()\n",
    "\n",
    "\n",
    "raw_data = np.random.rand(100, 5) * 100\n",
    "\n",
    "transformed_data = transform_pipeline(\n",
    "\traw_data, log_transform, standardize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def transform_pipeline(\n",
    "    data: np.ndarray, **transformers: dict[str, Callable]\n",
    ") -> np.ndarray:\n",
    "    for transformer_name, transformer_func in transformers.items():\n",
    "        if not callable(transformer_func):\n",
    "            raise ValueError(\n",
    "                f\"{transformer_name} is not callable\"\n",
    "            )\n",
    "\n",
    "        data = transformer_func(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def log_transform(data: np.ndarray) -> np.ndarray:\n",
    "    return np.log1p(data)\n",
    "\n",
    "\n",
    "def standardize(data: np.ndarray) -> np.ndarray:\n",
    "    return (data - data.mean()) / data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.random.rand(100, 5) * 100\n",
    "\n",
    "transformed_data = transform_pipeline(\n",
    "    raw_data,\n",
    "    log_transform=log_transform,\n",
    "    standardize=standardize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Decorators in Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Callable, List, Union\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def timer_decorator(func: Callable) -> Callable:\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"Function {func.__name__} took \"\n",
    "            f\"{end_time - start_time:.2f} seconds to execute.\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer_decorator\n",
    "def train_model(X: np.ndarray, y: np.ndarray | list[float]) -> None:\n",
    "    \"\"\"Simulating a time-consuming model training process\"\"\"\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.random.rand(1000, 10)\n",
    "    y = np.random.rand(1000)\n",
    "    train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"name: {train_model.__name__}\")\n",
    "print(f\"doc: {train_model.__doc__}\")\n",
    "print(f\"annotations: {train_model.__annotations__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "\n",
    "def timer_decorator(func: Callable) -> Callable:\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(\n",
    "            f\"Function {func.__name__} took \"\n",
    "            f\"{end_time - start_time:.2f} seconds to execute.\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}